{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "# 0: contradiction 1: entailment 2: neutral\n",
    "model = AutoModelForSequenceClassification.from_pretrained('textattack/bert-base-uncased-snli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def perturb_text(text):\n",
    "    text_list = text.split(' ')\n",
    "    text_perturbed = []\n",
    "    for delete in text.split(' '):\n",
    "        if delete.lower() in set(stopwords.words('english')):\n",
    "            continue\n",
    "        text_perturbed.append(\n",
    "            (' '.join(\n",
    "                ['[MASK]' if w == delete else w for w in text_list]), delete))\n",
    "\n",
    "    return text_perturbed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def exp(model, premise, hypothesis, k):\n",
    "    full_inp = tokenizer(premise, text_pair=hypothesis, return_tensors='pt')\n",
    "    logits = torch.softmax(model(**full_inp).logits[0], dim=-1)\n",
    "    orig_confidence, target_class = logits.max(-1)\n",
    "    target_class = target_class.item()\n",
    "    orig_confidence = orig_confidence.item()\n",
    "\n",
    "    # premise first\n",
    "    perturbed_premise = perturb_text(premise)\n",
    "    pre_confidences = []\n",
    "    for sent, _ in perturbed_premise:\n",
    "        inp = tokenizer(sent, text_pair=hypothesis, return_tensors='pt')\n",
    "        conf = torch.softmax(model(**inp).logits[0], dim=-1)[target_class].item()\n",
    "        conf = orig_confidence - conf\n",
    "        pre_confidences.append(conf)\n",
    "    \n",
    "    # perturb hypothesis\n",
    "    perturbed_hyp = perturb_text(hypothesis)\n",
    "    hyp_confidences = []\n",
    "    for sent, _ in perturbed_hyp:\n",
    "        inp = tokenizer(premise, text_pair=sent, return_tensors='pt')\n",
    "        conf = torch.softmax(model(**inp).logits[0], dim=-1)[target_class].item()\n",
    "        conf = orig_confidence - conf\n",
    "        hyp_confidences.append(conf)\n",
    "    \n",
    "    pre_topk = torch.tensor(pre_confidences).topk(k=min(k, len(pre_confidences)))[1].tolist()\n",
    "    hyp_topk = torch.tensor(hyp_confidences).topk(k=min(k, len(hyp_confidences)))[1].tolist()\n",
    "    topk_premises = [perturbed_premise[i] for i in pre_topk]\n",
    "    topk_hyp = [perturbed_hyp[i] for i in hyp_topk]\n",
    "\n",
    "    topk_pairs = list(itertools.product(topk_premises, topk_hyp))\n",
    "    final_confidences = []\n",
    "    for pair in topk_pairs:\n",
    "        inp = tokenizer(pair[0][0], text_pair=pair[1][0], return_tensors='pt')\n",
    "        conf = torch.softmax(model(**inp).logits[0], dim=-1)[target_class].item()\n",
    "        conf = orig_confidence - conf\n",
    "        final_confidences.append(conf)\n",
    "    \n",
    "    return target_class, orig_confidence, final_confidences, topk_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contradiction example\n",
    "# premise = \"I didn't think that the movie was that great.\"\n",
    "# hypothesis = \"The movie was excellent.\"\n",
    "# [(didn't + great <-> excellent)]\n",
    "\n",
    "# entailment example\n",
    "# premise = 'At the other end of Pennsylvania Avenue, people began to line up for a White House tour.'\t\n",
    "# hypothesis = 'People formed a line at the end of Pennsylvania Avenue.'\n",
    "# [(began to line up <-> formed a line)]\n",
    "\n",
    "# neutral example\n",
    "premise = \"Your gift is appreciated by each and every student who will benefit from your generosity.\"\t\n",
    "hypothesis = \"Hundreds of students will benefit from your generosity.\"\n",
    "# [each and every <-> Hundreds of]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def analyze_result(prediction, confidence, conf_drops, perturbations):\n",
    "    print('premise:', premise)\n",
    "    print('hypothesis:', hypothesis)\n",
    "    print()\n",
    "    class_map = ['contradiction', 'entailment', 'neutral']\n",
    "    print(f'original prediction was {class_map[prediction]} / with confidence: {confidence}\\n')\n",
    "    conf_drops = np.array(conf_drops)\n",
    "    idx = conf_drops.argsort(axis=0)[::-1]\n",
    "    conf_drops = conf_drops[idx]\n",
    "    perturbations = [perturbations[i] for i in idx]\n",
    "    pert_sents = [(s[0][0], s[1][0]) for s in perturbations]\n",
    "    pert_pre_words = set([s[0][1] for s in perturbations])\n",
    "    pert_hyp_words = set([s[1][1] for s in perturbations])\n",
    "\n",
    "    for i, (pert, conf) in enumerate(zip(pert_sents, conf_drops), 1):\n",
    "        print(f'{i}. {pert} | -{conf}')\n",
    "\n",
    "    print()\n",
    "    print('premise:', pert_pre_words, '\\nhypothesis:', pert_hyp_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise: Your gift is appreciated by each and every student who will benefit from your generosity.\n",
      "hypothesis: Hundreds of students will benefit from your generosity.\n",
      "\n",
      "original prediction was neutral / with confidence: 0.9418114423751831\n",
      "\n",
      "1. ('Your gift is appreciated by each and every student who will benefit from your [MASK]', '[MASK] of students will benefit from your generosity.') | -0.924758305773139\n",
      "2. ('Your gift is [MASK] by each and every student who will benefit from your generosity.', '[MASK] of students will benefit from your generosity.') | -0.9190915487706661\n",
      "3. ('Your gift is appreciated by each and every student who will [MASK] from your generosity.', '[MASK] of students will benefit from your generosity.') | -0.9189088735729456\n",
      "4. ('Your [MASK] is appreciated by each and every student who will benefit from your generosity.', '[MASK] of students will benefit from your generosity.') | -0.918523658066988\n",
      "5. ('Your gift is appreciated by each and every student who will [MASK] from your generosity.', 'Hundreds of students will benefit from your [MASK]') | --0.001528918743133545\n",
      "6. ('Your gift is [MASK] by each and every student who will benefit from your generosity.', 'Hundreds of students will benefit from your [MASK]') | --0.004618942737579346\n",
      "7. ('Your gift is appreciated by each and every student who will [MASK] from your generosity.', 'Hundreds of students will [MASK] from your generosity.') | --0.008300423622131348\n",
      "8. ('Your [MASK] is appreciated by each and every student who will benefit from your generosity.', 'Hundreds of students will benefit from your [MASK]') | --0.009805917739868164\n",
      "9. ('Your gift is [MASK] by each and every student who will benefit from your generosity.', 'Hundreds of students will [MASK] from your generosity.') | --0.014240801334381104\n",
      "10. ('Your [MASK] is appreciated by each and every student who will benefit from your generosity.', 'Hundreds of students will [MASK] from your generosity.') | --0.020615100860595703\n",
      "11. ('Your gift is appreciated by each and every student who will benefit from your [MASK]', 'Hundreds of students will benefit from your [MASK]') | --0.027974307537078857\n",
      "12. ('Your gift is appreciated by each and every student who will benefit from your [MASK]', 'Hundreds of students will [MASK] from your generosity.') | --0.035126686096191406\n",
      "13. ('Your gift is [MASK] by each and every student who will benefit from your generosity.', 'Hundreds of [MASK] will benefit from your generosity.') | --0.049510836601257324\n",
      "14. ('Your [MASK] is appreciated by each and every student who will benefit from your generosity.', 'Hundreds of [MASK] will benefit from your generosity.') | --0.049870312213897705\n",
      "15. ('Your gift is appreciated by each and every student who will [MASK] from your generosity.', 'Hundreds of [MASK] will benefit from your generosity.') | --0.050929486751556396\n",
      "16. ('Your gift is appreciated by each and every student who will benefit from your [MASK]', 'Hundreds of [MASK] will benefit from your generosity.') | --0.05112862586975098\n",
      "\n",
      "premise: {'appreciated', 'gift', 'generosity.', 'benefit'} \n",
      "hypothesis: {'students', 'generosity.', 'benefit', 'Hundreds'}\n"
     ]
    }
   ],
   "source": [
    "analyze_result(*exp(model, premise, hypothesis, k=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c2746b4c817b2e7822e65c51ec19822c8b0676bc7037025bbef03eb15b20d6a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('synch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
